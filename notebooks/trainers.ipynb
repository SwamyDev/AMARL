{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Trainers\n",
    "\n",
    "In this notebook I test trainer implementations on various environments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Monitoring setup\n",
    "This sets up the logging system to be able to monitor the training progress of the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s - %(levelname)s:%(name)s: %(message)s')\n",
    "logging.root.setLevel(logging.INFO)\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment factory\n",
    "This function produces the environment the agent is trained and evaluated on and applies all the necessary wrappers. It is also used by the evaluation function to validate the agent on a fresh environment instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env():\n",
    "    e = gym.make('BreakoutNoFrameskip-v4')\n",
    "    e = NoOpResetEnv(e)\n",
    "    e = MaxAndSkipEnv(e)\n",
    "    e = EpisodicLifeEnv(e)\n",
    "    e = OriginalReturnWrapper(e)\n",
    "    e = SignReward(e)\n",
    "    e = TorchObservation(e)\n",
    "    e = StackFrames(e, size=4)\n",
    "    return e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation function\n",
    "To evaluate the agent, a video is produces of one trajectory within the environment and sent to tensorboard. On Tensorboard one can then analyse the progress of the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_agent(trainable):\n",
    "    e = make_env()\n",
    "    video, rewards = render_trajectory(e, trainable.policy, reward_infos=['episodic_return'])\n",
    "    writer.add_video(\"trajectory\", video, trainable.steps_trained, fps=40)\n",
    "    writer.add_scalar(\"rewards/total\", rewards['total_reward'], trainable.steps_trained)\n",
    "    writer.add_scalar(\"returns/total\", rewards['total_episodic_return'], trainable.steps_trained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train the Agent\n",
    "In the part I actually train the agent on one of the testing environments. It is a good idea to look at the gym unit\n",
    "testing environment first and try to solve that. If this doesn't work, there is something wrong either with the\n",
    "algorithm or the setup. Also make sure to sanity check input signal. Here the problem was that the input image was\n",
    "actually completely mangled by the torch vision pipeline because I used it wrong initally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import amarl\n",
    "import gym\n",
    "from amarl.messenger import monitor, LogMonitor, CombinedMonitor, TensorboardMonitor\n",
    "from amarl.trainers import A2CTrainer\n",
    "from amarl.visualisation import render_trajectory\n",
    "from amarl.wrappers import MultipleEnvs, active_gym, OriginalReturnWrapper, SignReward, TorchObservation, StackFrames, \\\n",
    "    NoOpResetEnv, MaxAndSkipEnv, EpisodicLifeEnv\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter()\n",
    "log_monitor = LogMonitor(logger, progress_averaging=100, performance_sample_size=10000)\n",
    "tb_monitor = TensorboardMonitor(writer, 10, scalars=dict(episodic_return='returns/episodic'))\n",
    "\n",
    "env = MultipleEnvs(make_env, num_envs=16)\n",
    "with active_gym(env) as env, monitor(CombinedMonitor([log_monitor, tb_monitor])) as monitor:\n",
    "    com = A2CTrainer(env, config={'rollout_horizon': 5, 'device': 'cuda'})\n",
    "    try:\n",
    "        amarl.run(com, num_steps=int(1e5), step_frequency_fns={int(2e4): evaluate_agent})\n",
    "    finally:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Plot Results\n",
    "It is easier to understand how the agent is performing by plotting the metrics of the training. Sum bugs can be subtle,\n",
    "for instance it was not that obvious that the frame stack ordering was wrong, because the agent still learned a good\n",
    "policy and performed reasonably well. Because of such subtle bugs the algorithm can become more sensitive to certain\n",
    "hyper-parameters (i.e. gradient clipping), resulting in a misleading perception of importance of these parameters. Be\n",
    "careful!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def moving_average(a, n=3):\n",
    "    ret = np.cumsum(np.insert(a, 0, 0))\n",
    "    return (ret[n:] - ret[:-n]) / n\n",
    "\n",
    "scores = monitor.captured_returns\n",
    "avg_window = 100\n",
    "scores_avg = moving_average(scores, avg_window)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(range(len(scores)), scores)\n",
    "start = avg_window // 2\n",
    "ax.plot(range(start, start + len(scores_avg)), scores_avg)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
